#!/usr/bin/env python
# coding: utf-8

# In[6]:


import MeCab
import re
import pandas as pd
import pprint
import emoji
import urllib.request
import unicodedata
import string
import numpy as np


# # å‰å‡¦ç†

def preprocessing(tweet_path):#(tweetæƒ…å ±ã‚’æ ¼ç´ã—ãŸcsvãƒ•ã‚¡ã‚¤ãƒ«ã®path)
    """
    tweetã¨profileã‚’å‰å‡¦ç†ã™ã‚‹é–¢æ•°
    """
    df = pd.read_csv(tweet_path,engine='python',index_col=0)
    #åˆ†æã®å¦¥å½“æ€§ã®ãŸã‚ã«åŒä¸€äººç‰©ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å‰Šé™¤
    df = df[~df.duplicated(subset='user_id', keep='last')].reset_index(drop=True)
    #tweetã®å‡¦ç†
    tweet_lst = df.loc[:,["tweet"]].values.tolist()
    processed_tweet = []

    #ç‰¹æ®Šè¨˜å·ãƒªã‚¹ãƒˆ
    pattern = '[!"#$%&\'\\\\()*+,-. ğ“‚ƒğ“ˆ’ğ“¸ âœ« â–· âˆ á¢Ì«á¢ â˜ ââââââ â€“ Ã¤ â—ŸÌ½Ì½ï¹† âœ¿ á’ â•± Ãˆ âŒ— â–‘â–‘â–‘â–’â–“â–“â–’â–‘â–‘â–‘  ğ“Š â€¢â€¢Ã©Ã± ğ–¥»ğ–¥» â«â« Â¿ êÒ‚ğ“„¹Ã»Ã¨â€¢â€™â€¢Ã§Ã£Ãªâ˜­ /:;<=>? Â¬ Ã¼ ğ“† ÏˆÏˆâ˜‰â˜¾ @[\\]^_`{|}~ Ì‡â¸œà¥‚ â—¡â—œà¿â— á… á… á… â €â €â€¦ â€™ â€™ Ã­ã€Œã€Ğ” ã‚å®šï¸âƒ£ï¸âƒ£ à¹‘âƒ™âƒ˜ËŠ Â« âœ§âœµâœ§âœµâœ§à¼†â€”â•°â”€â›Ë—ËË‹ËË— ÏƒÂ´Ïƒ Ã¡ â¤·âƒ¤ â€˜ âˆ™ , ãƒ»ãƒ»;ãƒ» ...   á·„   â”ã‚š ã‚šâ”êª”Ì¤Ì®êª”Ì¤ ç½’ áœ¦  á› Ùˆ  Ë†ÎŸË†  â€Ù© ââ  ê’³ Û¶Â» Ì€  ã€‡ã€”ã€•â€œâ€â—‡á´—â—â†“â†’â™ªâ˜…âŠ‚âŠƒâ€»â–³â–¡â— ã€œ á»  Ìã€ˆã€‰âŒ˜  Ã³Ì´Ì¶Ì·Ì¥  â™¡ â†‘ â†“ â†’ â†ã€ã€ã€ã€‘ï¼†ï¼Šãƒ»ã€ã€‘â—ã……â—Ğ¤â˜†âœ©ï¸â™¡â†’â†â–¼â‘ â‘¡â‘¢â‘£â‘¤ã€ã€Ï‰ã€Šã€‹âˆ âˆ‡âˆ©â™ªâˆ€â—à½€CÑ‰â‰§â‰¦ Ìâ—¤â—¢â– â—†â˜…â€»â†‘â†“ã€‡â—¯â—‹â—â‡’â–½â—‰Î˜â™«â™¬ã€ƒâ€œâ€â—‡á„‰âŠ‚âŠƒĞ´ Ù« ï¼ˆï¼‰ï¼„ï¼ƒï¼ ã€‚ã€ï¼Ÿï¼ï½€ï¼‹ï¿¥ï¼…,]'
    
    for tweet in tweet_lst:
        tweet = str(tweet)
        tweet = tweet = unicodedata.normalize("NFKC", tweet)  # å…¨è§’è¨˜å·ã‚’åŠè§’ã¸ç½®æ›
        tweet = re.sub(r'[!-~]', "", tweet)#åŠè§’è¨˜å·,æ•°å­—,è‹±å­—ã‚’å‰Šé™¤
        tweet = ''.join(['' if c in emoji.UNICODE_EMOJI else c for c in tweet]) # çµµæ–‡å­—å‰Šé™¤
        tweet = re.sub(r"(https?|ftp)(:\/\/[-_\.!~*\'()a-zA-Z0-9;\/?:\@&=\+$,%#]+)", "" ,tweet)#URLå‰Šé™¤
        tweet =  re.sub(pattern, '', tweet) # ä¸è¦è¨˜å·å‰Šé™¤
        tweet = re.sub("[?:u3000|amp|xa|n]","",tweet)#æ¼ã‚Œã‚’å¾®èª¿æ•´
        if tweet =='':#å‰å‡¦ç†ã—ãŸçµæœç©ºæ¬„ã«ãªã£ãŸã‚‰å‰Šé™¤å¯¾è±¡ã«
            tweet = None
        processed_tweet.append(tweet)


    #profileã®å‡¦ç†
    profile_lst = df.loc[:,["profile"]].values.tolist() 
    processed_profile = []
    for profile in profile_lst:
        profile = str(profile)
        profile = profile = unicodedata.normalize("NFKC", profile)  # å…¨è§’è¨˜å·ã‚’åŠè§’ã¸ç½®æ›
        profile = re.sub(r'[!-~]', "", profile)#åŠè§’è¨˜å·,æ•°å­—,è‹±å­—ã‚’å‰Šé™¤
        profile = ''.join(['' if c in emoji.UNICODE_EMOJI else c for c in profile]) # çµµæ–‡å­—å‰Šé™¤
        profile = re.sub(r"(https?|ftp)(:\/\/[-_\.!~*\'()a-zA-Z0-9;\/?:\@&=\+$,%#]+)", "" ,profile)#URLå‰Šé™¤
        profile =  re.sub(pattern, '', profile) # ä¸è¦è¨˜å·å‰Šé™¤
        profile = re.sub("[?:u3000|amp|xa|n]","",profile)#æ¼ã‚Œã‚’å¾®èª¿æ•´
        if profile =='':#å‰å‡¦ç†ã—ãŸçµæœç©ºæ¬„ã«ãªã£ãŸã‚‰å‰Šé™¤å¯¾è±¡ã«
            profile = None
        processed_profile.append(profile)
            
    processed_df = pd.DataFrame(processed_profile,columns=["processed_profile"])
    processed_df["processed_tweet"] = processed_tweet

    df = pd.concat([df,processed_df],axis=1)
    df = df.dropna(how="any").reset_index(drop=True)
    print("åˆ†æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã¯{}ä»¶ã§ã™".format(df.shape[0]))
    
    return df

if __name__ == "__main__":
    tweetdata_name = input("åˆ†æã™ã‚‹twitterãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’dataãƒ•ã‚©ãƒ«ãƒ€ã«å…¥ã‚Œã¦ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„(.csvã¾ã§)")
    tweet_path = "data/{}".format(tweetdata_name)
    df = preprocessing(tweet_path)
    df.to_csv("data/processed.csv")
    print("å‰å‡¦ç†ã—ãŸçµæœã‚’dataãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¾ã—ãŸ")
